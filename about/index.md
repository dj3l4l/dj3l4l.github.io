---
layout: page
title: About
date: 2022-03-29
comments: false
---

## The Purpose of this Blog

This blog is a place for me to share fascinating insights on past and present breakthroughs in applied mathematics and probability theory. It is also a place for me to share the projects that I create; designed to illustrate the value (and I hope, the joy) of those breakthroughs and insights.

If a person comes away from this blog thinking, "wow, that *is* interesting, I never thought of it that way", then it will have achieved what I dreamed for it to do.

## A Longer Tale of My Personal Interests and Motivations

At the start of 2022, I stopped working on a tech startup that I co-founded with a dear friend of mine. At that point, I decided to spend the next year working solely on personal projects; designed to further my understanding of Bayesian decision theory. This may sound strange to some. Why spend a whole year on Bayesian decision theory - is it really so interesting? Is it really so complex? And is the return on that sort of investment worth it? 

The answer I have to those questions is an emphatic "YES". The reason for that answer begins in the fact that, for much of my adult life, I have been absolutely fascinated (nay, obsessed) with explainable automated algorithms (or, as is the current popular name --- Explainable AI). Explainable algorithms are algoirithms that are not only designed to make automated decisions, but that also provide human beings with *interpretable reasons* for those decisions. In the most fascinating of cases, explainable algorithms can teach human beings new things about the world around us: sometimes even about topics that poeple thought had nothing new to offer.

And so, at the start of 2022, I asked myself: "How can I be a part of the future of explainable AI? How can I contribute? What are the possible frontiers that my humble mind can comprehend?" And, after much deliberation, I came to believe that those frontiers would lie in as-yet undiscovered innovations of decision theory and probabilistic reasoning. After all, aren't the most valuable decisions about outcomes that are uncertain? Then, if we are to create truly transparent "thinking machines", surely we must find systems of logic that are capable of translating all forms of logical uncertainty into human language (and vice versa)?

Thankfully, such a daunting task is not one that we must embark on from scratch. For the hundred years or so, Bayesian probability theory has been used as a rational means by which to express subjective, partial knowledge as objective, well-defined numbers. It has even been proven that these numerical forms are precisely analogous to fundamental axioms of logic (that is, if a decision violates the rules of Bayesian inference, the it must neccesarily violate formal rules of logic).

Whilst going over the works of pioneers in this field (such as Jeffreys, Jaynes and even Laplace and Gibbs!), it suddenly became apparent to me that a large body of work from the early 50s to the late 80s contains incredibly important, but mostly forgotten insights. Though perhaps not completely forgotten, many important insights regarding Bayesian inference were trapped in academic niches, from times where the computer was still in its infancy and analytical (not computational) solutions limited the applicability of such important ideas.

It then became my goal to create a website (this website), on which I would publish these partially forgotten important concepts, in the hopes of illustrating to many how they may connect to much more modern and pressing issues: for example, how can we measure, track and remove unwanted bias from our automated decision processes? The goal of this website is also to demonstrate the value of these ideas by publishing open-source code from personal projects that use them in clear and understandable ways.

There is no way for me to know when we will obtain a paradigm-shifting breakthrough in Explainable AI, but I am confident that whatever and whenever such a breakthrough will happen, it will not be solely due to the discovery of new and exotic methods for encoding and decoding **patterns** but, rather, answers to questions such as: "Which patterns in a given context constitute **knowledge**, what do we mean when we say we **learn** them and how can describe **subjective** knowledge in a **universally objective** way?".


## A Brief Technical Run-Down of my Past

In 2011, I received an MSci in Astronomy and Physics from UCL. My Masters thesis was on "Black Hole Thermodynamics and the Information Loss Paradox", and my advisor was [Prof. Ian Ford](https://www.ucl.ac.uk/physics-astronomy/people/professor-ian-ford).

I then went on to obtain a PhD in the Physics of Astronomical Detectors from the [Quantum Sensors Group](https://www.phy.cam.ac.uk/research/research-groups/qs) at the Cavendish Laboratory, University of Cambridge. My PhD advisor was [Prof. Stafford Withington](https://www.phy.cam.ac.uk/directory/withingtons), and my thesis was  titled "Thermal Transport and Noise in Micro-Engineered Support Structures for Detector Applications": an investigation in [novel methods for the accurate simulation of heat transport](https://aip.scitation.org/doi/10.1063/1.4893019), and for the utilisation of phase-coherent thermal waves to create low-dimensional "heat interferometers". The application of this form of heat interferometry was [proven empirically (for the first time)](https://aip.scitation.org/doi/10.1063/1.5041348) to reduce noise in superconducting detectors.

I graduated from Cambridge in 2016, and went on to co-found an augmented reality startup, called [Sention](https://www.linkedin.com/company/21145650/admin/), with my good friend [Alexander Bridi](https://www.linkedin.com/in/zanbridi/). Whilst at Sention, I researched and developed novel and innovative solutions to a broad range of unsolved computer vision problems: from 100% pixel-accurate real-time video segmentation, to 3D scene reconstruction from under-constrained single-camera views, to blind real-time lens distortion correction (to state just a few). All research and algorithms from my time at Sention were proprietary.

