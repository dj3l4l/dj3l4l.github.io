---
layout: page
title: About
date: 2022-03-29
comments: false
---

## The Purpose of this Blog

This blog is a place for me to share fascinating insights on past and present breakthroughs in applied mathematics and probability theory. It is also a place for me to share the projects that I create; designed to illustrate the value (and I hope, the joy) of those breakthroughs and insights.

If a person comes away from this blog thinking, "wow, that *is* interesting, I never thought of it that way", then it will have achieved what I dreamed for it to do.

## A Long Tale of My Personal Interests and Motivations

At the start of 2022, I stopped working on a startup that a good friend an I co-founded. At that point, I decided to spend the next year working solely on personal projects; designed to further my understanding of Bayesian decision theory. This may sound strange to some. Why spend a whole year on Bayesian decision theory - is it really so interesting? Is it really so complex? And is the return on that sort of investment worth it? 

The answer I have to those questions is an emphatic "YES". The reason for that answer begins in the fact that, for much of my adult life, I have been absolutely fascinated (nay, obsessed) with explainable automated algorithms (or, in modern vernacular, Explainable AI). Explainable algorithms are those that are not only designed to make automated decisions, but that also provide human beings with *interpretable reasons* for those decisions. In the most fascinating of cases, explainable algorithms can teach human beings new things about the world around us: sometimes about topics people believe have nothing new to offer.

And so, at the start of 2022, I asked myself: "How can I contribute to the future of explainable AI? What are the possible frontiers that my humble mind can comprehend?" And, after much deliberation, I came to believe that those frontiers would lie in as-yet undiscovered innovations of decision theory and probabilistic reasoning. After all, aren't the most valuable decisions about uncertain outcomes? Then, if we are to create truly transparent "thinking machines", must we not find an objective way to translate any uncertainty into human language (and vice versa)?

Thankfully, such a daunting task is not one that we must embark on from scratch. For the past hundred years or so, Bayesian probability theory has been used as an objective means to express subjective, partial knowledge in numberical form. It has been proven that those objective rules mirror the axioms of logic (that is, if a decision violates the rules of Bayesian inference, then it must also violate logic).

Whilst reading the original works of key Bayesian pioneers (such as Jeffreys, Jaynes, Gibbs(!) and Laplace(!!)), it suddenly became apparent to me that a large body of work from the early 50s to the late 80s contained incredibly important, but mostly forgotten insights. Though perhaps not *completely* forgotten, many important discoveries regarding Bayesian inference remain trapped in academic niches: and from times when the computer was still in its infancy, and when analytical (not computational) solutions were limiting their applicability.

It then became my goal to create a website (this website), on which I would publish partially forgotten important concepts from the past, in the hopes of illustrating to others how such concepts connect to much more modern and pressing questions: for example, how can we measure, track and remove unwanted bias from automated decision processes?

There is no way for me to know when we will obtain a paradigm-shifting breakthrough in Explainable AI, but I am confident that whatever and whenever such a breakthrough will happen, it will not be due to the discovery of new and exotic methods for encoding and decoding **patterns** but, rather, it will come from answers to questions such as: "Which patterns in a given context constitute **knowledge**; what do we mean when we say we **learn**, and how can we describe **subjective** knowledge in a **universally objective, interpetable language**?".


## A Brief Rundown of My Technical Achievements

In 2011, I received an MSci in Astronomy and Physics from UCL. My Masters thesis was on "Black Hole Thermodynamics and the Information Loss Paradox", and my advisor was [Prof. Ian Ford](https://www.ucl.ac.uk/physics-astronomy/people/professor-ian-ford).

I then went on to obtain a PhD in the Physics of Astronomical Detectors from the [Quantum Sensors Group](https://www.phy.cam.ac.uk/research/research-groups/qs) at the Cavendish Laboratory, University of Cambridge. My PhD advisor was [Prof. Stafford Withington](https://www.phy.cam.ac.uk/directory/withingtons), and my thesis was  titled "Thermal Transport and Noise in Micro-Engineered Support Structures for Detector Applications": an investigation in [novel methods for the accurate simulation of heat transport](https://aip.scitation.org/doi/10.1063/1.4893019), and for the utilisation of phase-coherent thermal waves to create low-dimensional "heat interferometers". The application of this form of heat interferometry was [proven empirically (for the first time)](https://aip.scitation.org/doi/10.1063/1.5041348) to reduce noise in superconducting detectors.

I graduated from Cambridge in 2016, and went on to co-found an augmented reality startup, called [Sention](https://www.linkedin.com/company/21145650/admin/), with my good friend [Alexander Bridi](https://www.linkedin.com/in/zanbridi/). Whilst at Sention, I researched and developed novel and innovative solutions to a broad range of unsolved computer vision problems: from 100% pixel-accurate real-time video segmentation, to 3D scene reconstruction from under-constrained single-camera views, to blind real-time lens distortion correction (to state just a few). All research and algorithms from my time at Sention were proprietary.

